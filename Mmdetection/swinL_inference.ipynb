{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import (build_dataloader, build_dataset, replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "import os\n",
    "from mmcv.parallel import MMDataParallel\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "# config file 들고오기\n",
    "cfg = Config.fromfile('/opt/ml/detection/baseline/mmdetection/configs/object/trash.py')\n",
    "\n",
    "root='/opt/ml/detection/dataset/'\n",
    "\n",
    "epoch = 'best_bbox_mAP_50_epoch_1'\n",
    "\n",
    "# dataset config 수정\n",
    "cfg.data.test.classes = classes\n",
    "cfg.data.test.img_prefix = root\n",
    "cfg.data.test.ann_file = root + 'test.json'\n",
    "# cfg.data.test.pipeline[1]['img_scale'] = (512,512) # Resize\n",
    "cfg.data.test.test_mode = True\n",
    "cfg.work_dir = '/opt/ml/detection/baseline/mmdetection/work_dirs/swinL_final'\n",
    "\n",
    "# cfg.data.samples_per_gpu = 4\n",
    "\n",
    "cfg.seed=2021\n",
    "cfg.gpu_ids = [1]\n",
    "\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
    "cfg.model.train_cfg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# build dataset & dataloader\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /opt/ml/detection/baseline/mmdetection/work_dirs/swinL_final/best_bbox_mAP_50_epoch_1.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.0.fc_cls.weight: copying a param with shape torch.Size([11, 1024]) from checkpoint, the shape in current model is torch.Size([81, 1024]).\n",
      "size mismatch for roi_head.bbox_head.0.fc_cls.bias: copying a param with shape torch.Size([11]) from checkpoint, the shape in current model is torch.Size([81]).\n",
      "size mismatch for roi_head.bbox_head.1.fc_cls.weight: copying a param with shape torch.Size([11, 1024]) from checkpoint, the shape in current model is torch.Size([81, 1024]).\n",
      "size mismatch for roi_head.bbox_head.1.fc_cls.bias: copying a param with shape torch.Size([11]) from checkpoint, the shape in current model is torch.Size([81]).\n",
      "size mismatch for roi_head.bbox_head.2.fc_cls.weight: copying a param with shape torch.Size([11, 1024]) from checkpoint, the shape in current model is torch.Size([81, 1024]).\n",
      "size mismatch for roi_head.bbox_head.2.fc_cls.bias: copying a param with shape torch.Size([11]) from checkpoint, the shape in current model is torch.Size([81]).\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = os.path.join(cfg.work_dir, f'{epoch}.pth')\n",
    "\n",
    "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg')) # build detector\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu') # ckpt load\n",
    "\n",
    "model.CLASSES = dataset.CLASSES\n",
    "model = MMDataParallel(model.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>] 4871/4871, 0.4 task/s, elapsed: 11512s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "output = single_gpu_test(model, data_loader, show_score_thr=0.0001) # output 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.23s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 0.40404445 811.8698 2.0483637 1020.4124 27.2...</td>\n",
       "      <td>test/0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 0.4725972 952.3398 3.2536342 1020.5143 37.43...</td>\n",
       "      <td>test/0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 0.3860508 190.0966 2.7600532 411.8033 51.307...</td>\n",
       "      <td>test/0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>test/0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 0.50428444 1.2887532 4.695411 79.01531 41.47...</td>\n",
       "      <td>test/0004.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    PredictionString       image_id\n",
       "0  0 0.40404445 811.8698 2.0483637 1020.4124 27.2...  test/0000.jpg\n",
       "1  0 0.4725972 952.3398 3.2536342 1020.5143 37.43...  test/0001.jpg\n",
       "2  0 0.3860508 190.0966 2.7600532 411.8033 51.307...  test/0002.jpg\n",
       "3                                                     test/0003.jpg\n",
       "4  0 0.50428444 1.2887532 4.695411 79.01531 41.47...  test/0004.jpg"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_strings = []\n",
    "file_names = []\n",
    "coco = COCO(cfg.data.test.ann_file)\n",
    "img_ids = coco.getImgIds()\n",
    "\n",
    "class_num = 10\n",
    "for i, out in enumerate(output):\n",
    "    prediction_string = ''\n",
    "    image_info = coco.loadImgs(coco.getImgIds(imgIds=i))[0]\n",
    "    for j in range(class_num):\n",
    "        for o in out[j]:\n",
    "            prediction_string += str(j) + ' ' + str(o[4]) + ' ' + str(o[0]) + ' ' + str(o[1]) + ' ' + str(\n",
    "                o[2]) + ' ' + str(o[3]) + ' '\n",
    "        \n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(image_info['file_name'])\n",
    "\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv(os.path.join(cfg.work_dir, f'submission_{epoch}.csv'), index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/0003.jpg\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2378/3051279407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# class 별 bbox 색\n",
    "colors = [\n",
    "    (255, 0, 0), \n",
    "    (0, 255, 0),\n",
    "    (0, 0, 255),\n",
    "    (127, 127, 0),\n",
    "    (127, 0, 127),\n",
    "    (0, 127, 127),\n",
    "    (200, 200, 200),\n",
    "    (50, 150, 200),\n",
    "    (200, 155, 50),\n",
    "    (130, 198, 20),\n",
    "]\n",
    "labels = {0: 'General trash', 1: 'Paper', 2: 'Paper pack', 3: 'Metal', 4: 'Glass', 5: 'Plastic', 6: 'Styrofoam', 7: 'Plastic bag', 8: 'Battery', 9: 'Clothing'}\n",
    "\n",
    "# 이미지 경로\n",
    "img_dir = '/opt/ml/detection/dataset/'\n",
    "# output 파일 경로\n",
    "output_dir = '/opt/ml/detection/baseline/mmdetection/work_dirs/swinL_final/submission_best_bbox_mAP_50_epoch_1.csv'\n",
    "# output_dir = '/opt/ml/detection/dataset/train.json'\n",
    "\n",
    "test_result = pd.read_csv(output_dir)\n",
    "\n",
    "file_names = test_result['image_id'].values.tolist()\n",
    "bboxes = test_result['PredictionString'].values.tolist()\n",
    "\n",
    "idx = 3\n",
    "# idx = 13\n",
    "file_name = file_names[idx]\n",
    "print(file_name)\n",
    "bbox = bboxes[idx].split()\n",
    "\n",
    "image = cv2.imread(os.path.join(img_dir, file_name)).astype(np.uint8)\n",
    "for i in range(0, len(bbox), 6):\n",
    "    label = int(bbox[i])\n",
    "    x_min = int(bbox[i + 2].split('.')[0])\n",
    "    y_min = int(bbox[i + 3].split('.')[0])\n",
    "    x_max = int(bbox[i + 4].split('.')[0])\n",
    "    y_max = int(bbox[i + 5].split('.')[0])\n",
    "    \n",
    "    # bounding box 그리기\n",
    "    image = cv2.rectangle(image, pt1=(x_min, y_min), pt2=(x_max, y_max), color=colors[label], thickness=5)\n",
    "    # label text 넣기\n",
    "    cv2.putText(image, labels[label], (x_min, y_min - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, colors[label], 3)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2d617e4e4c71290b58af84e5aa30aeb780f45b049d7dc2bd64c8742d6fa340d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('openmlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
